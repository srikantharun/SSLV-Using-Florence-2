{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Analysis of Spacetech Designs for SSLV Using Florence-2\n",
    "\n",
    "This Jupyter Notebook demonstrates multimodal analysis of Small Satellite Launch Vehicle (SSLV) designs using **Florence-2**, a state-of-the-art vision-language model released by Microsoft in January 2025. The demo is tailored for spacetech applications, focusing on Tamil Nadu's growing spacetech ecosystem (e.g., startups like Agnikul Cosmos, ToSpace). We perform tasks such as:\n",
    "- **Image Captioning**: Describe SSLV components.\n",
    "- **Object Detection**: Identify parts like nozzles or fairings.\n",
    "- **Segmentation**: Isolate components for quality control.\n",
    "- **Visual Question Answering (VQA)**: Answer design-related questions.\n",
    "\n",
    "## Objectives\n",
    "- Showcase Florence-2's capabilities in spacetech design analysis.\n",
    "- Integrate OpenCV for image processing and PyTorch for model inference.\n",
    "- Use datasets like SPEED+ and synthetic SSLV images.\n",
    "- Address practical problems: quality control, mission planning, design validation.\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.8+\n",
    "- Libraries: `torch`, `transformers`, `opencv-python`, `diffusers`, `datasets`, `PIL`\n",
    "- GPU recommended (e.g., Google Colab Pro or local NVIDIA GPU)\n",
    "- Hugging Face account and token for gated models\n",
    "\n",
    "## Datasets\n",
    "- **SPEED+**: Stanford's Spacecraft Pose Estimation Dataset (synthetic and hardware-in-the-loop images of satellites, relevant for SSLV components). Available at Stanford Digital Repository.\n",
    "- **Synthetic SSLV Images**: Generated using Stable Diffusion 3.5 with prompts like \"SSLV rocket nozzle in space\".\n",
    "- Optional: Public satellite imagery (e.g., NASA's Earth Observatory) for context.\n",
    "\n",
    "## Setup\n",
    "Install dependencies and authenticate with Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision opencv-python transformers diffusers datasets pillow\n",
    "from huggingface_hub import login\n",
    "login(\"your_huggingface_token\")  # Replace with your token\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Florence-2 Model\n",
    "Florence-2 is a lightweight vision-language model trained on the FLD-5B dataset (126M images, 5.4B annotations). It supports tasks like captioning, detection, segmentation, and VQA using a prompt-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Florence-2-large\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    trust_remote_code=True\n",
    ").to(device)\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"microsoft/Florence-2-large\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic SSLV Images\n",
    "Since real SSLV images are limited, we use **Stable Diffusion 3.5** to generate synthetic images of SSLV components (e.g., rocket nozzle, fairing). This simulates designs for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3.5-large\",\n",
    "    torch_dtype=torch_dtype\n",
    ").to(device)\n",
    "\n",
    "prompt = \"A detailed SSLV rocket nozzle in space, high-resolution, realistic, with metallic texture\"\n",
    "image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "image.save(\"sslv_nozzle.png\")\n",
    "\n",
    "# Display synthetic image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Synthetic SSLV Nozzle\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load SPEED+ Dataset\n",
    "The SPEED+ dataset contains synthetic and hardware-in-the-loop images of spacecraft, suitable for SSLV component analysis. We load a sample image for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: SPEED+ requires downloading from Stanford Digital Repository.\n",
    "# For demo, use a placeholder image or download a sample from Hugging Face.\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Placeholder: Replace with SPEED+ image of a satellite component\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(\"SPEED+ Sample Image (Placeholder)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multimodal Analysis with Florence-2\n",
    "We perform four tasks to analyze SSLV designs:\n",
    "- **Image Captioning**: Describe the component.\n",
    "- **Object Detection**: Identify parts like nozzles or panels.\n",
    "- **Segmentation**: Isolate components for quality control.\n",
    "- **VQA**: Answer design-related questions.\n",
    "\n",
    "### Helper Function\n",
    "Define a function to run Florence-2 tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_florence_task(image, task_prompt, text_input=None):\n",
    "    prompt = task_prompt if text_input is None else task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=1024,\n",
    "        num_beams=3\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=task_prompt,\n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "    return parsed_answer\n",
    "\n",
    "# Convert PIL Image to OpenCV format for visualization\n",
    "def pil_to_cv2(image):\n",
    "    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Image Captioning\n",
    "Generate a description of the SSLV nozzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sslv_image = Image.open(\"sslv_nozzle.png\")\n",
    "caption = run_florence_task(sslv_image, \"<CAPTION>\")\n",
    "print(\"Caption:\", caption)\n",
    "\n",
    "# Visualize with OpenCV\n",
    "cv_image = pil_to_cv2(sslv_image)\n",
    "cv2.putText(cv_image, caption, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "cv2.imshow(\"Captioned Image\", cv_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Object Detection\n",
    "Detect components like the nozzle or structural elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = run_florence_task(sslv_image, \"<OD>\", \"rocket nozzle, structural frame\")\n",
    "print(\"Detected Objects:\", detection)\n",
    "\n",
    "# Visualize bounding boxes\n",
    "cv_image = pil_to_cv2(sslv_image)\n",
    "for box in detection['<OD>']['bboxes']:\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cv2.rectangle(cv_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(cv_image, \"Nozzle\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Object Detection\", cv_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Segmentation\n",
    "Segment the nozzle for quality control (e.g., defect detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = run_florence_task(sslv_image, \"<SEGMENTATION>\", \"rocket nozzle\")\n",
    "print(\"Segmentation Masks:\", segmentation)\n",
    "\n",
    "# Visualize mask\n",
    "cv_image = pil_to_cv2(sslv_image)\n",
    "mask = segmentation['<SEGMENTATION>']['masks'][0]  # First mask\n",
    "mask = cv2.resize(mask, (cv_image.shape[1], cv_image.shape[0]))\n",
    "masked_image = cv2.bitwise_and(cv_image, cv_image, mask=mask.astype(np.uint8))\n",
    "\n",
    "cv2.imshow(\"Segmented Nozzle\", masked_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Visual Question Answering (VQA)\n",
    "Answer a design-related question about the SSLV component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What material is the rocket nozzle made of?\"\n",
    "vqa_answer = run_florence_task(sslv_image, \"<VQA>\", question)\n",
    "print(\"VQA Answer:\", vqa_answer)\n",
    "\n",
    "# Visualize with question and answer\n",
    "cv_image = pil_to_cv2(sslv_image)\n",
    "cv2.putText(cv_image, f\"Q: {question}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "cv2.putText(cv_image, f\"A: {vqa_answer}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "cv2.imshow(\"VQA Result\", cv_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Applications in Spacetech\n",
    "- **Quality Control**: Object detection and segmentation identify defects in SSLV components (e.g., cracks in nozzles), supporting Tamil Nadu's Space Bays manufacturing.\n",
    "- **Mission Planning**: Captioning and VQA provide insights for mission design, e.g., analyzing thermal properties of components.\n",
    "- **Design Validation**: Synthetic images allow iterative testing of SSLV designs before prototyping, reducing costs for startups like Agnikul Cosmos.\n",
    "- **Automation**: Multimodal analysis automates inspection in Kulasekarapattinam spaceport operations.\n",
    "\n",
    "## 6. Challenges and Future Work\n",
    "- **Data Scarcity**: Real SSLV images are limited; synthetic datasets need validation.\n",
    "- **Model Fine-Tuning**: Fine-tune Florence-2 on spacetech-specific datasets for better accuracy.\n",
    "- **Real-Time Inference**: Optimize for real-time analysis in manufacturing.\n",
    "- **Integration with CFD**: Combine with Computational Fluid Dynamics (CFD) for aerodynamic analysis (future scope).\n",
    "\n",
    "## 7. Conclusion\n",
    "This notebook demonstrates Florence-2's multimodal capabilities for SSLV design analysis, integrating OpenCV, PyTorch, and Hugging Face tools. It addresses spacetech challenges in Tamil Nadu's ecosystem, supporting startups and ISRO's initiatives. Extend this demo by:\n",
    "- Using real SPEED+ images.\n",
    "- Fine-tuning Florence-2 on custom SSLV datasets.\n",
    "- Adding CFD simulations for aerodynamic validation.\n",
    "\n",
    "## References\n",
    "- Florence-2: https://huggingface.co/microsoft/Florence-2-large\n",
    "- SPEED+: Stanford Digital Repository\n",
    "- Stable Diffusion 3.5: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
    "- Tamil Nadu Space Policy: https://startuptn.in/"
   ]
  }
 ]
}